{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Intro to Data Science Ethics\n",
    "\n",
    "_Authors: Greg Baker (SYD), Justin Pounders, and Matt Brems_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Describe some of the political, ethical and economic ramifications of data science.\n",
    "- Critically think about positive and negative uses of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## Introduction: legal and ethical responsibilities\n",
    "\n",
    "As data scientists, we often have access to very personal information about \n",
    "our customers or users and **we are asked or required to make decisions based on that data**.\n",
    "\n",
    "Many countries have very strict laws on how such data must be handled, but we all have a professional responsibility to act *ethically*.\n",
    "\n",
    "### Warning\n",
    "\n",
    "Laws change -- sometimes quite suddenly -- and General Assembly doesn't\n",
    "promise that anything in this topic won't be out-of-date by the time you\n",
    "finish the class.\n",
    "\n",
    "Also, _I AM NOT A LAWYER_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the context?\n",
    "\n",
    "Data science involves gathering data and using that data to draw inferences and make predictions.\n",
    "\n",
    "- Creditors want to know how reliable you are.\n",
    "- Insurance companies want to know how risky you are.\n",
    "- Dating sites want to know what your \"type\" is.\n",
    "- Retailers want to know what you will buy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/target.png)\n",
    "\n",
    "> https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/#53d014186668\n",
    "\n",
    "**The upshot**\n",
    "\n",
    "- Target assigned customers an ID;\n",
    "- They tracked all purchases;\n",
    "- They linked IDs to demographic data when available;\n",
    "- They learned to predict pregnancy (even due dates!!);\n",
    "\n",
    "> \"But even if you’re following the law, you can do things where people get queasy.” Target statistician Andrew Pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we care?\n",
    "\n",
    "Machine learning and other data-based decision-making algorithms can have...\n",
    "\n",
    "- **immediate** ramifications because humans are bypassed and machines work fast and on a large scale;\n",
    "- **impact** directly on people in ways that affect their livelihoods;\n",
    "- **invisible** reach, i.e., how much of your data is collected? Who owns it?  Where is it stored?\n",
    "\n",
    "![](assets/chowdhury.png)\n",
    "\n",
    "> Taken from Rumman Chowdhury's presentation at the Southern Data Science Conference, 2018.\n",
    ">\n",
    "> Links to articles\n",
    "> - [Here's how Centrelink can win back Australians' trust after the robo-debt debacle](http://www.abc.net.au/news/2017-03-21/how-centrelink-can-win-back-trust-after-the-robo-debt-debacle/8372788); analysis [here](http://www.rogerclarke.com/DV/CRD17.html)\n",
    "> - [Facebook Lets Advertisers Exclude Users by Race](https://www.propublica.org/article/facebook-lets-advertisers-exclude-users-by-race); NYTimes article [here](https://www.nytimes.com/2016/11/12/business/media/facebook-will-stop-some-ads-from-targeting-users-by-race.html).\n",
    "> - [I asked Tinder for my data. It sent me 800 pages of my deepest, darkest secrets](https://www.theguardian.com/technology/2017/sep/26/tinder-personal-data-dating-app-messages-hacked-sold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food for thought\n",
    "\n",
    "- Did Centrelink do anything \"wrong?\"  What did they _not_ consider?\n",
    "- What about Facebook?\n",
    "- Who owns your data?  (Tinder or otherwise.)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OKCupid\n",
    "\n",
    "![](assets/okcupid.png)\n",
    "\n",
    "> http://fortune.com/2014/07/28/okcupid-we-experiment-on-users-too/\n",
    "\n",
    "### Food for thought:\n",
    "\n",
    "- Websites use \"A/B testing\" all the time.  Is this different?  Why?\n",
    "- How could OK Cupid possibly have performed this experiment in a more ethical manner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cambridge Analytica\n",
    "\n",
    "> **\"The firm offered tools that could identify the personalities of American voters and influence their behavior.\"**\n",
    "\n",
    "![](assets/cambridge1.png)\n",
    "\n",
    "---\n",
    "\n",
    "![](assets/cambridge2.png)\n",
    "\n",
    "> https://www.nytimes.com/2018/03/19/technology/facebook-cambridge-analytica-explained.html\n",
    "\n",
    "### Food for thought?\n",
    "\n",
    "- Did users consent to have their data scraped?\n",
    "- Is Facebook culpable?\n",
    "- What would you do if you saw this happen, either at Facebook, the university or Cambridge Analytica?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "----\n",
    "\n",
    "## Racial \"profiling\" by country\n",
    "\n",
    "<img src=\"assets/France.png\" style=\"float: left; margin: 10px; height: 50px\">\n",
    "\n",
    "### France - you must not ask about race\n",
    "\n",
    "<br>\n",
    "\n",
    "<blockquote>Race is such a taboo term that a 1978 law specifically banned the collection and computerized storage of race-based data without the express consent of the interviewees or a waiver by a state committee. France therefore collects no census or other data on the race (or ethnicity) of its citizens.  [Race policy in France](https://www.brookings.edu/articles/race-policy-in-france/)\n",
    "</blockquote>\n",
    "\n",
    "Even if you don't use race in your model, you simply can't store this in a database or even\n",
    "have it appear in a pandas dataframe.\n",
    "\n",
    "\n",
    "### Malaysia - you must ask about race\n",
    "\n",
    "<br>\n",
    "\n",
    "<blockquote>\n",
    "Race is such an important term in Malaysia and the history of discrimination so\n",
    "strong, that there are great efforts to make sure that companies aren't being discriminatory \n",
    "or racist. It is quite\n",
    "common to collect some quite personal data about every customer, student or user:\n",
    "\n",
    "<ul>\n",
    "<li> _What is your race?_\n",
    "<li> _What is your religion?_\n",
    "</ul>\n",
    "\n",
    "These are written on everyone's national identity card and stored in numerous databases.\n",
    "Changing religion requires completing a formal application and being issued with a new \n",
    "identity card.\n",
    "</blockquote>\n",
    "\n",
    "If you are dealing with data from Malaysia it will be important to show that any algorithm you \n",
    "use doesn't adversely affect people of different religions as a court can easily request data \n",
    "on your per-race outcomes. Analysing student education \n",
    "outcomes to confirm no racial or religius bias is important, for example.\n",
    "\n",
    "So you will definitely need to do generate some descriptive statistics on race, for example.\n",
    "\n",
    "### Side-note:\n",
    "\n",
    "This makes it very difficult for a French university to open a campus in Malaysia!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is the underlying ethical motivation, and how does it affect data scientists?\n",
    "\n",
    "\n",
    "- Generally, countries set up laws so that the colour of your skin or what you believe shouldn't affect how\n",
    "you are treated by other human beings.\n",
    "- But many decisions are now being made by _algorithms_, rather than human beings.\n",
    "\n",
    "> That's the first rule of algorithms.\n",
    "> Algorithms are **opinions embedded in code**.\n",
    "> ...\n",
    "> (As data scientists), we should not be the arbiters of truth. We should be translators of ethical discussions that happen in larger society.\n",
    "> --- [Cathy O'Neill TED Talk](https://www.ted.com/talks/cathy_o_neil_the_era_of_blind_faith_in_big_data_must_end/transcript)\n",
    "\n",
    "- Data scientists have a unique responsibility to make algorithms that **treat everyone fairly**, just as you would\n",
    "expect a human being to treat everyone fairly.\n",
    "- In Europe, this is now a **legal responsibility**, which will mostly fall on data scientists: justify why your\n",
    "model is reasonable and fair.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do you **know** you're right?  Can you know??\n",
    "\n",
    "![](./assets/compas.png)\n",
    "\n",
    "> https://www.washingtonpost.com/news/monkey-cage/wp/2016/10/17/can-an-algorithm-be-racist-our-analysis-is-more-cautious-than-propublicas/?noredirect=on&utm_term=.475a0b30d2aa\n",
    "\n",
    "Also see this analysis: [The accuracy, fairness, and limits of predicting recidivism](http://advances.sciencemag.org/content/4/1/eaao5580.full)\n",
    "\n",
    "\n",
    "### Food for thought:\n",
    "\n",
    "- Algorithmic decision making is **not easy**.\n",
    "- Was Northpointe's \"product\" impactful to people's livelihoods?\n",
    "- Could they _explain why_ they were making the predictions that were being made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting Data\n",
    "\n",
    "#### Recently, lots of data have been hacked and released:\n",
    "- Facebook\n",
    "- Experian Credit\n",
    "- Office of Personnel Management (OPM)\n",
    "- Ashley Madison\n",
    "\n",
    "In an era where it seems like data will eventually be released no matter what, how does this change the calculus around the collection of data?\n",
    "\n",
    "As you collect data:\n",
    "- Do I really need to collect this?\n",
    "- What steps will I take to protect this data?\n",
    "- Think about the worst-case scenario: What would happen if your data fell into the worst possible hands?\n",
    "\n",
    "#### How can we share incomes... without sharing incomes? \n",
    "- Person 1 has salary $s_1$.\n",
    "- Person 2 has salary $s_2$.\n",
    "- Person 3 has salary $s_3$.\n",
    "- Each person picks a large random \"noise\" number, $n_1$, $n_2$, $n_3$. *Do not tell this to anybody.*\n",
    "\n",
    "- Person 1 tells **only** person 2 the value of $s_1 + n_1$.\n",
    "- Person 2 then adds their values and tells **only** person 3 the value of $s_1 + n_1 + s_2 + n_2$.\n",
    "- Person 3 then adds their values and tells **only** person 1 the value of $s_1 + n_1 + s_2 + n_2 + s_3 + n_3$.\n",
    "- Person 1 then subtracts their random \"noise\" and tells **only** person 2 the value of $s_1 + s_2 + n_2 + s_3 + n_3$.\n",
    "- Person 2 then subtracts their random \"noise\" and tells **only** person 3 the value of $s_1 + s_2 + s_3 + n_3$.\n",
    "- Person 3 then subtracts their random \"noise\" and tells everyone the value of $s_1 + s_2 + s_3$.\n",
    "\n",
    "#### How can I gather data about drug use... without getting data about drug use?\n",
    "- As an experimenter, I ask the question, \"Have you used heroin in the past 30 days?\"\n",
    "- As the respondent, you flip a coin. *You do not show me, the experimenter.*\n",
    "    - If you flip heads, flip again. If you flip heads a second time, then say \"Yes.\" If you flip tails, then say \"No.\"\n",
    "    - If you flip tails on your first flip, then respond with the true answer.\n",
    "- This way, if someone responds \"yes\" or \"no,\" I don't know if they actually did or did not use heroin.\n",
    "- For a large sample size $n$, our estimate of the percentage of people who use heroin is given by $\\hat{p}_H = 2\\hat{p}_{yes} - \\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Ethical Considerations\n",
    "\n",
    "- Confidentiality vs. Anonymity\n",
    "- Data Ownership\n",
    "- Consent\n",
    "- Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='resources'></a>\n",
    "\n",
    "## Additional resources\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- [Is there are a right to explanation for Machine Learning in the GDPR?](https://iapp.org/news/a/is-there-a-right-to-explanation-for-machine-learning-in-the-gdpr)\n",
    "- [Why a Right to Explanation of Automated Decision-Making Does Not Exist in the General Data Protection Regulation](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2903469)\n",
    "- [Towards Interpretable Reliable Models](https://blog.kjamistan.com/towards-interpretable-reliable-models/)\n",
    "- [GDPR and you](https://blog.kjamistan.com/gdpr-you-my-talk-at-cloudera-sessions-munchen/)\n",
    "- [Hold Your Machine Learning and AI Models Accountable](https://medium.com/pachyderm-data/hold-your-machine-learning-and-ai-models-accountable-de887177174c)\n",
    "- [How GDPR Affects Data Science](https://kdnuggets.com/2017/07/gdpr-affects-data-science.html)\n",
    "- [Scaleable Bayesian rule lists](https://arxiv.org/pdf/1602.08610v2.pdf)\n",
    "\n",
    "- [Why Should I Trust You? Explaining the Predictions of Any Classfier ](https://www.youtube.com/watch?v=hUnRCxnydCc)\n",
    "- [Explaining Complex Machine Learning Models with LIME](https://datascienceplus.com/explaining-complex-machine-learning-models-with-lime/)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
